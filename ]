import os
import numpy as np

from network import Network
from functions.loss_funcs import loss_dict, error_dict
from functions.act_funcs import act_dict
from functions.init_funcs import init_dict
from functions.metric_funcs import metr_dict
from optimizer import GradientDescent
from utils.data_handler import read_monk
from utils.hype_search import grid_search, kfold_cv
from utils.debug_tools import Plotter


def forward_test():
    in_vec = np.array([[3, 3]])
    exp_res = np.array([[12, 12]])

    net = Network([2, 2, 2], None, act_dict["identity"],
                  act_dict["identity"], loss_dict["squared"])

    out = net.forward(in_vec)

    return np.equal(out, exp_res).all()


def backward_test():
    in_vec = np.array([[3, 3]])
    exp_res = np.array([[6, 6]])

    net = Network([2, 2, 2], None, act_dict["identity"],
                  act_dict["identity"], loss_dict["squared"])

    out = net.forward(in_vec)
    net.backward(exp_res, out)

    bool_res = True

    for i, layer in enumerate(net.layers):
        bool_res = bool_res and np.equal(layer.grad_w, np.array([[36, 36]])).all()

        if i == 0:
            bool_res = bool_res and np.equal(layer.grad_b, np.array([[12, 12]])).all()
        elif i == 1:
            bool_res = bool_res and np.equal(layer.grad_b, np.array([[6, 6]])).all()

    return bool_res


def simple_learning_test_regression():
    train_x = np.array([[3, 3]])
    train_y = np.array([[6, 6]])

    net = Network([2, 2, 2], init_dict["norm"], act_dict["sigm"],
                  act_dict["identity"], loss_dict["squared"])

    gd = GradientDescent(0.5, -1, stop_crit_type="delta_w", epsilon=0.01)
    gd.train(net, train_x, train_y)

    return net.forward(train_x), gd.epoch_count


def simple_and_learning_test_classification():  # Func: A and B
    train_x = np.asarray(np.matrix('0 0; 0 1; 1 0; 1 1'))
    train_y = np.asarray(np.matrix('0; 0; 0; 1'))

    net = Network([2, 1],
                  init_dict["std"],
                  act_dict["relu"],
                  act_dict["sigm"],
                  loss_dict["nll"])

    gd = GradientDescent(0.2, 1, lr_decay=True, lr_decay_tau=100,
                         momentum_val=0.99, stop_crit_type="delta_w", epsilon=0.01)
    gd.train(net, train_x, train_y)

    net_pred = net.forward(train_x)
    net_pred[net_pred < 0.5] = 0
    net_pred[net_pred >= 0.5] = 1

    return metr_dict["accuracy"](train_y, net_pred), gd.epoch_count


def simple_learning_test_classification():  # Func: (A or B) xor (C or D)
    train_x = np.asarray(
        np.matrix('0 0 0 0; 0 1 0 1; 0 0 0 1; 0 1 0 0; 1 0 0 0; 1 0 1 0; 1 1 1 1'))
    train_y = np.asarray(np.matrix('0; 0; 1; 1; 1; 0; 0'))

    dict_param_net = {
        'conf_layers': [4, 2, 1],
        'init_func': init_dict["norm"],
        'act_func': act_dict["tanh"],
        'out_func': act_dict["sigm"],
        'loss_func': loss_dict["nll"]
    }

    dict_param_sgd = {
        'lr': 0.01,
        'batch_size': 1,
        'reg_val': 0.9,
        'reg_type': 2,
        'momentum_val': 0.9,
        'nesterov': False,
        'lr_decay': True,
        'lr_decay_tau': 50,
        'stop_crit_type': 'delta_w',
        'epsilon': 0.001,
        'patient': 5
    }

    net = Network(**dict_param_net)

    plotter = Plotter(["lr_curve", "lr", "act_val", "grad_norm"],
                      [error_dict["nll"], metr_dict["miscl. error"]], 2)
    gd = GradientDescent(0.5, 1, lr_decay=True, momentum_val=0.99, lr_decay_tau=100,
                         stop_crit_type="delta_w", epsilon=0.01, patient=20)
    gd.train(net, train_x, train_y, plotter=plotter)
    plotter.plot()

    net_pred = net.forward(train_x)
    net_pred[net_pred < 0.5] = 0
    net_pred[net_pred >= 0.5] = 1

    return metr_dict["accuracy"](train_y, net_pred), gd.epoch_count


def test_monk_grid_search(path_train, path_test):
    train_x, train_y = read_monk(path_train)
    test_x, test_y = read_monk(path_test)

    dict_param_net = {
        'conf_layers': [[6, 6, 1]],
        'init_func': [init_dict["norm"]],
        'act_func': [act_dict["tanh"]],
        'out_func': [act_dict["sigm"]],
        'loss_func': [loss_dict["nll"]]
    }

    dict_param_sgd = {
        'lr': [0.01, 0.2],
        'batch_size': [-1, 20],
        'reg_val': [0, 0.9],
        'reg_type': [2],
        'momentum_val': [0, 0.9],
        'nesterov': [False, True],
        'lim_epochs': [200],
        'lr_decay': [True, False],
        'lr_decay_tau': [50, 100],
        'stop_crit_type': ['fixed', 'delta_w'],
        'epsilon': [0.001, 0.0001],
        'patient': [5]
    }

    metric = error_dict["nll"]
    best_result, best_combo = grid_search(train_x, train_y,
                                          dict_param_net, dict_param_sgd, 5, metric)

    print(f"Best {metric.name} score (train): ", best_result)

    print('init_func: ' + best_combo[0]['init_func'].name)
    print('act_func: ' + best_combo[0]['act_func'].name)
    print('out_func: ' + best_combo[0]['out_func'].name)
    print('loss_func: ' + best_combo[0]['loss_func'].name)
    print(best_combo[1])

    return best_result

def test_monk(path_train, path_test):
    train_x, train_y = read_monk(path_train, norm_data=False)
    test_x, test_y = read_monk(path_test, norm_data=False)

    dict_param_net = {
        'conf_layers': [6, 6, 1],
        'init_func': init_dict["norm"],
        'act_func': act_dict["tanh"],
        'out_func': act_dict["sigm"],
        'loss_func': loss_dict["nll"]
    }

    dict_param_sgd = {
        'lr': 0.5,
        'batch_size': 20,
        'reg_val': 0,
        'reg_type': 2,
        'momentum_val': 0.6,
        'nesterov': False,
        'lim_epochs': 500,
        'lr_decay': True,
        'lr_decay_tau': 450,
        'stop_crit_type': 'delta_w',
        'epsilon': 0.01,
        'patient': 10
    }

    metric1 = error_dict["nll"]
    metric2 = metr_dict["miscl. error"]

    res = kfold_cv(dict_param_net, dict_param_sgd, train_x, train_y, 5,
                   metric2, plot_bool=True, n_runs=10)

    net = Network(**dict_param_net)
    gd = GradientDescent(**dict_param_sgd)

    plotter = Plotter(["lr_curve", "lr", "act_val", "grad_norm"],
                      [metric1, metric2], 2)
    gd.train(net, train_x, train_y, plotter=plotter)
    plotter.plot()

    return res[1]


print("Forward test: ", forward_test())
print("Backward test: ", backward_test())

reg_res = simple_learning_test_regression()
print(f"Simple regression test: {reg_res[0]}, epochs: {reg_res[1]}")

clas1_res = simple_and_learning_test_classification()
print(f"Simple AND classification test: {clas1_res[0]}, epochs: {clas1_res[1]}")

print("Simple classification test: ", simple_learning_test_classification())
exit()

# Tests on monk1
path_train_monk1 = os.path.join('datasets', 'monks-1.train')
path_test_monk1 = os.path.join('datasets', 'monks-1.test')
print("Monk 1 score on validation set:", test_monk(path_train_monk1, path_test_monk1))
